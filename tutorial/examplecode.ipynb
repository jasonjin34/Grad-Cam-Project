{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy example\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size D_in is input dimension\n",
    "# H is hiddeen dimension, D_out is output dimension\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "# here is just basic matrix multiplication\n",
    "# dot multiplication\n",
    "# 64*1000 product 1000*100 product 100*10 generate 64*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial learning rate\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25220473.01207943\n",
      "1 20436712.20574233\n",
      "2 17887771.120564952\n",
      "3 15674688.151887111\n",
      "4 13223201.728475519\n",
      "5 10466220.309567917\n",
      "6 7828674.089663807\n",
      "7 5575803.938385295\n",
      "8 3881481.758839852\n",
      "9 2682272.704659152\n",
      "10 1879535.213058867\n",
      "11 1347751.956711391\n",
      "12 997441.0177290025\n",
      "13 762349.5634726391\n",
      "14 601017.2020980911\n",
      "15 486557.6044887745\n",
      "16 402795.84842065966\n",
      "17 339363.81582998135\n",
      "18 289841.2565564209\n",
      "19 250154.07182404073\n",
      "20 217678.44840819653\n",
      "21 190634.22009661092\n",
      "22 167783.3212868447\n",
      "23 148315.73686835173\n",
      "24 131567.69622105407\n",
      "25 117060.92598512763\n",
      "26 104419.59275807123\n",
      "27 93372.83208870832\n",
      "28 83669.79297062446\n",
      "29 75118.11549764522\n",
      "30 67556.7993441596\n",
      "31 60851.67584236468\n",
      "32 54895.0003024038\n",
      "33 49597.2277741266\n",
      "34 44872.15921098893\n",
      "35 40650.10599673036\n",
      "36 36888.9631313586\n",
      "37 33533.07331042309\n",
      "38 30517.899778858282\n",
      "39 27802.860087475372\n",
      "40 25353.7358148751\n",
      "41 23143.108584431728\n",
      "42 21143.981892249772\n",
      "43 19339.281894549866\n",
      "44 17704.55592392879\n",
      "45 16220.114983228199\n",
      "46 14870.813823219582\n",
      "47 13643.510046009826\n",
      "48 12527.234636679183\n",
      "49 11509.817777012973\n",
      "50 10582.715897046528\n",
      "51 9735.860383688134\n",
      "52 8961.898208540977\n",
      "53 8254.07010464184\n",
      "54 7605.947919339737\n",
      "55 7012.453001159716\n",
      "56 6468.490445364256\n",
      "57 5969.203124702199\n",
      "58 5511.0156033564335\n",
      "59 5090.34531230914\n",
      "60 4704.031383517142\n",
      "61 4348.720388546579\n",
      "62 4021.84764254753\n",
      "63 3720.927247457723\n",
      "64 3443.8016528093176\n",
      "65 3188.47729386438\n",
      "66 2953.0334831680166\n",
      "67 2735.9367369577076\n",
      "68 2535.6954399260085\n",
      "69 2350.8368544875702\n",
      "70 2180.0048221800366\n",
      "71 2022.246381857775\n",
      "72 1876.5754659653553\n",
      "73 1741.970426485386\n",
      "74 1617.4435197035057\n",
      "75 1502.1759989079992\n",
      "76 1395.4925497711436\n",
      "77 1296.7444206444777\n",
      "78 1205.3076785124742\n",
      "79 1120.5600403227431\n",
      "80 1042.0313080546975\n",
      "81 969.1791440490321\n",
      "82 901.6325297646931\n",
      "83 838.9602443430986\n",
      "84 780.8166196121924\n",
      "85 726.852849129582\n",
      "86 676.7636351104265\n",
      "87 630.2804361463566\n",
      "88 587.1752264762102\n",
      "89 547.1144406233957\n",
      "90 509.88601970631964\n",
      "91 475.3007419369483\n",
      "92 443.13992669232033\n",
      "93 413.2176273936075\n",
      "94 385.3855831154061\n",
      "95 359.49559968919203\n",
      "96 335.41147259777745\n",
      "97 312.98790329308343\n",
      "98 292.10970015096694\n",
      "99 272.66951314979235\n",
      "100 254.5646286755721\n",
      "101 237.69788842018056\n",
      "102 221.98571211348894\n",
      "103 207.33937168337476\n",
      "104 193.6920678653829\n",
      "105 180.96400300700518\n",
      "106 169.10377444305567\n",
      "107 158.04034233693886\n",
      "108 147.7217507706069\n",
      "109 138.09413318266013\n",
      "110 129.11530674218596\n",
      "111 120.74080475045227\n",
      "112 112.92463743991591\n",
      "113 105.62748280584785\n",
      "114 98.81441188216945\n",
      "115 92.45335577198748\n",
      "116 86.51244483620998\n",
      "117 80.96334620915127\n",
      "118 75.78103160049471\n",
      "119 70.9371685250924\n",
      "120 66.41496851086262\n",
      "121 62.18905726290114\n",
      "122 58.23828984845963\n",
      "123 54.5448169060584\n",
      "124 51.09438934299759\n",
      "125 47.865897430057075\n",
      "126 44.84703035973229\n",
      "127 42.023449142681955\n",
      "128 39.382640829097966\n",
      "129 36.91135321270765\n",
      "130 34.599787715362964\n",
      "131 32.43646003884072\n",
      "132 30.41144438468519\n",
      "133 28.51624065848511\n",
      "134 26.741644499089972\n",
      "135 25.080532004767434\n",
      "136 23.525786347047557\n",
      "137 22.06912968643394\n",
      "138 20.704975379911065\n",
      "139 19.427343393935306\n",
      "140 18.23044130942269\n",
      "141 17.10913937522878\n",
      "142 16.058345018489895\n",
      "143 15.073394617724091\n",
      "144 14.150707941039627\n",
      "145 13.286052591217185\n",
      "146 12.47530431006826\n",
      "147 11.715153901345053\n",
      "148 11.002868178218764\n",
      "149 10.33447828880137\n",
      "150 9.707799885255888\n",
      "151 9.119876646937332\n",
      "152 8.568630555714371\n",
      "153 8.051380635435994\n",
      "154 7.5660105773051445\n",
      "155 7.110750486928108\n",
      "156 6.683444196211585\n",
      "157 6.282341994069077\n",
      "158 5.905978776076173\n",
      "159 5.5527495366706\n",
      "160 5.22108284582966\n",
      "161 4.909802076821326\n",
      "162 4.617475007580129\n",
      "163 4.343010723178287\n",
      "164 4.08515170943828\n",
      "165 3.84294505163611\n",
      "166 3.615477722617134\n",
      "167 3.4017297674432934\n",
      "168 3.2009159867429045\n",
      "169 3.0120868854461302\n",
      "170 2.8346587236537024\n",
      "171 2.667883337072018\n",
      "172 2.5112158485373826\n",
      "173 2.3639238769579745\n",
      "174 2.225485176094617\n",
      "175 2.0953631392000074\n",
      "176 1.9729951143901543\n",
      "177 1.8579400670230293\n",
      "178 1.7497566979264585\n",
      "179 1.648020497980803\n",
      "180 1.5523174727277795\n",
      "181 1.4623064683722038\n",
      "182 1.3776563884500856\n",
      "183 1.2980095395449651\n",
      "184 1.2230714749647522\n",
      "185 1.1525686861759057\n",
      "186 1.0862088018039227\n",
      "187 1.023749295393232\n",
      "188 0.9649953186717002\n",
      "189 0.9096715843687913\n",
      "190 0.8575908785379585\n",
      "191 0.8085671915821457\n",
      "192 0.7623932309010596\n",
      "193 0.7189282212667225\n",
      "194 0.6779972368012352\n",
      "195 0.6394441087284541\n",
      "196 0.6031333881321383\n",
      "197 0.5689336135706838\n",
      "198 0.5367069473871247\n",
      "199 0.5063626674906114\n",
      "200 0.47776586653232156\n",
      "201 0.450815122033559\n",
      "202 0.42542778892737804\n",
      "203 0.4015009342396958\n",
      "204 0.37895666335463074\n",
      "205 0.35770191682883434\n",
      "206 0.3376578471362993\n",
      "207 0.3187657874383734\n",
      "208 0.3009533129455347\n",
      "209 0.28415602895928405\n",
      "210 0.2683215839458193\n",
      "211 0.253383713090222\n",
      "212 0.2392960815687089\n",
      "213 0.22601364692098197\n",
      "214 0.21348232865327543\n",
      "215 0.2016613565342045\n",
      "216 0.1905089197641217\n",
      "217 0.17998341234450965\n",
      "218 0.1700572579249934\n",
      "219 0.16068612549723155\n",
      "220 0.15184692278865486\n",
      "221 0.14350107837066234\n",
      "222 0.13562257436639225\n",
      "223 0.1281885859701898\n",
      "224 0.12116885843098985\n",
      "225 0.11454266744277289\n",
      "226 0.10828675662767928\n",
      "227 0.1023778598443204\n",
      "228 0.0968004216730092\n",
      "229 0.09153058514877242\n",
      "230 0.086554574587029\n",
      "231 0.08185494583814847\n",
      "232 0.07741486861916555\n",
      "233 0.07322228105796232\n",
      "234 0.06925948305304458\n",
      "235 0.06551653324428666\n",
      "236 0.06197990650901519\n",
      "237 0.05863772310202262\n",
      "238 0.055480504604873596\n",
      "239 0.05249518145071022\n",
      "240 0.04967479923579181\n",
      "241 0.047007988129074495\n",
      "242 0.044487327053804246\n",
      "243 0.04210477792814835\n",
      "244 0.039851713613369893\n",
      "245 0.037722652955918035\n",
      "246 0.035708743854624\n",
      "247 0.033804680581026765\n",
      "248 0.03200388687411944\n",
      "249 0.030300741454389015\n",
      "250 0.028690230139037404\n",
      "251 0.027166605273829407\n",
      "252 0.02572586097105057\n",
      "253 0.024362350776662666\n",
      "254 0.023072763294564286\n",
      "255 0.021852584626078163\n",
      "256 0.020698424410210234\n",
      "257 0.019606415074691894\n",
      "258 0.018572553965028615\n",
      "259 0.01759458665786973\n",
      "260 0.016668554483200412\n",
      "261 0.015792518707350458\n",
      "262 0.014963126844130398\n",
      "263 0.014178151506465286\n",
      "264 0.013435000500461414\n",
      "265 0.012731444046106901\n",
      "266 0.012065473968158727\n",
      "267 0.011434793523901655\n",
      "268 0.010837941029929726\n",
      "269 0.010272444965542079\n",
      "270 0.009737095454410096\n",
      "271 0.009229988605009676\n",
      "272 0.0087498065475719\n",
      "273 0.008295013294089711\n",
      "274 0.007864182215845176\n",
      "275 0.007456167497733969\n",
      "276 0.0070696004993680405\n",
      "277 0.006703506754446758\n",
      "278 0.006356497015491894\n",
      "279 0.006027866759844305\n",
      "280 0.00571638823863139\n",
      "281 0.005421318576719078\n",
      "282 0.005141659455699176\n",
      "283 0.004876678503422513\n",
      "284 0.004625541183577645\n",
      "285 0.004387504022927343\n",
      "286 0.0041619546020714064\n",
      "287 0.003948095527476653\n",
      "288 0.0037454865784020694\n",
      "289 0.0035533344287097058\n",
      "290 0.003371263061142736\n",
      "291 0.0031985616247785058\n",
      "292 0.003034910299795268\n",
      "293 0.002879678871954369\n",
      "294 0.0027325437268350527\n",
      "295 0.002592993626574261\n",
      "296 0.002460705336543075\n",
      "297 0.002335235689566453\n",
      "298 0.0022162551604678503\n",
      "299 0.0021034314741830732\n",
      "300 0.0019963928998923365\n",
      "301 0.0018948936978911493\n",
      "302 0.001798601653667113\n",
      "303 0.0017072895532873676\n",
      "304 0.0016206357914855382\n",
      "305 0.0015384735375211398\n",
      "306 0.0014604890778956037\n",
      "307 0.0013865473613293407\n",
      "308 0.0013163594087035693\n",
      "309 0.0012497893348357002\n",
      "310 0.0011866150543759014\n",
      "311 0.0011266804565852313\n",
      "312 0.0010697989910326221\n",
      "313 0.001015825543915799\n",
      "314 0.0009646029827567841\n",
      "315 0.0009159943916618197\n",
      "316 0.0008698669255981755\n",
      "317 0.00082608251394614\n",
      "318 0.0007845306298326426\n",
      "319 0.000745083303900987\n",
      "320 0.000707651319759615\n",
      "321 0.0006721073380262567\n",
      "322 0.0006383822237454201\n",
      "323 0.0006063511543012417\n",
      "324 0.000575965008999858\n",
      "325 0.000547097518823854\n",
      "326 0.0005197050164204316\n",
      "327 0.0004936852800242255\n",
      "328 0.00046899254255908967\n",
      "329 0.00044553588244525624\n",
      "330 0.00042327529711541287\n",
      "331 0.0004021306287231828\n",
      "332 0.0003820563028865751\n",
      "333 0.000362988302557646\n",
      "334 0.0003448843032266096\n",
      "335 0.00032768787369316237\n",
      "336 0.00031136114003928894\n",
      "337 0.00029585125875694195\n",
      "338 0.00028112272625831225\n",
      "339 0.0002671327191176784\n",
      "340 0.0002538463211670511\n",
      "341 0.00024122648886042147\n",
      "342 0.0002292381124788539\n",
      "343 0.00021785154010581847\n",
      "344 0.00020703388699059032\n",
      "345 0.00019676001471854583\n",
      "346 0.00018699745208865652\n",
      "347 0.0001777256955193494\n",
      "348 0.0001689145265301291\n",
      "349 0.00016054674364768552\n",
      "350 0.00015259432490690114\n",
      "351 0.00014504181810519838\n",
      "352 0.00013786310447328626\n",
      "353 0.00013104467387327817\n",
      "354 0.0001245630360318522\n",
      "355 0.00011840747062052917\n",
      "356 0.00011255472438332814\n",
      "357 0.000106996582212213\n",
      "358 0.0001017123330302528\n",
      "359 9.669344080908006e-05\n",
      "360 9.192143927767418e-05\n",
      "361 8.738876410231072e-05\n",
      "362 8.307908233220484e-05\n",
      "363 7.898514129535429e-05\n",
      "364 7.509248399967861e-05\n",
      "365 7.13944596095271e-05\n",
      "366 6.787835670185247e-05\n",
      "367 6.453808027980579e-05\n",
      "368 6.13618226932281e-05\n",
      "369 5.834377136145257e-05\n",
      "370 5.5474367319198784e-05\n",
      "371 5.274772123395295e-05\n",
      "372 5.015523802635808e-05\n",
      "373 4.769132740119269e-05\n",
      "374 4.5348663083600926e-05\n",
      "375 4.3122340667312344e-05\n",
      "376 4.100559552763805e-05\n",
      "377 3.899349173689164e-05\n",
      "378 3.708043608497426e-05\n",
      "379 3.526194628660651e-05\n",
      "380 3.353304515597162e-05\n",
      "381 3.188946296402381e-05\n",
      "382 3.0326732959101603e-05\n",
      "383 2.8841121531697938e-05\n",
      "384 2.742876623307862e-05\n",
      "385 2.6085791765123278e-05\n",
      "386 2.4808859701619654e-05\n",
      "387 2.3594715938014905e-05\n",
      "388 2.244041627854391e-05\n",
      "389 2.134289065069822e-05\n",
      "390 2.0299279590505726e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 1.930677548571153e-05\n",
      "392 1.8363217280887622e-05\n",
      "393 1.746584494658353e-05\n",
      "394 1.6612666009273227e-05\n",
      "395 1.5801135408149313e-05\n",
      "396 1.502962555052009e-05\n",
      "397 1.429578539675676e-05\n",
      "398 1.359812171725985e-05\n",
      "399 1.2934431800743253e-05\n",
      "400 1.2303502565916743e-05\n",
      "401 1.1703265867888594e-05\n",
      "402 1.1132669605265784e-05\n",
      "403 1.0589744381321495e-05\n",
      "404 1.0073632747514874e-05\n",
      "405 9.58254362076861e-06\n",
      "406 9.115765183162233e-06\n",
      "407 8.671537608590919e-06\n",
      "408 8.249313493974419e-06\n",
      "409 7.847486111578851e-06\n",
      "410 7.465534092407711e-06\n",
      "411 7.102005462544298e-06\n",
      "412 6.756437955772525e-06\n",
      "413 6.427557760467173e-06\n",
      "414 6.114950500407685e-06\n",
      "415 5.817432070611437e-06\n",
      "416 5.5345738289676825e-06\n",
      "417 5.265379607852174e-06\n",
      "418 5.009462012712021e-06\n",
      "419 4.765895430068454e-06\n",
      "420 4.534320455531505e-06\n",
      "421 4.3139370404577315e-06\n",
      "422 4.1043980944614975e-06\n",
      "423 3.9049753464709385e-06\n",
      "424 3.7153551465814417e-06\n",
      "425 3.5348897843013273e-06\n",
      "426 3.3633097704198193e-06\n",
      "427 3.200001813310762e-06\n",
      "428 3.044709248975021e-06\n",
      "429 2.8969058435167298e-06\n",
      "430 2.7563636112915418e-06\n",
      "431 2.6226042403732326e-06\n",
      "432 2.49540936696452e-06\n",
      "433 2.374343408971642e-06\n",
      "434 2.2592256505409533e-06\n",
      "435 2.149655138429024e-06\n",
      "436 2.0454552254600272e-06\n",
      "437 1.9462766420284888e-06\n",
      "438 1.8519564645096602e-06\n",
      "439 1.7621905795028513e-06\n",
      "440 1.6768245589457543e-06\n",
      "441 1.595563932558143e-06\n",
      "442 1.5182832796424075e-06\n",
      "443 1.4447308878334417e-06\n",
      "444 1.3747754600223808e-06\n",
      "445 1.308186845677529e-06\n",
      "446 1.24485246483005e-06\n",
      "447 1.1845721020589794e-06\n",
      "448 1.1272399819430685e-06\n",
      "449 1.072668363050069e-06\n",
      "450 1.0207615463072568e-06\n",
      "451 9.713585704252825e-07\n",
      "452 9.243660925642438e-07\n",
      "453 8.796377308139899e-07\n",
      "454 8.370888431716556e-07\n",
      "455 7.965923554314944e-07\n",
      "456 7.580704337142951e-07\n",
      "457 7.214065229577766e-07\n",
      "458 6.865254597377378e-07\n",
      "459 6.533302641148905e-07\n",
      "460 6.217495745806965e-07\n",
      "461 5.916921965350403e-07\n",
      "462 5.630940140631376e-07\n",
      "463 5.358776740478788e-07\n",
      "464 5.099837681878396e-07\n",
      "465 4.853406995727449e-07\n",
      "466 4.618926359265933e-07\n",
      "467 4.395768278997095e-07\n",
      "468 4.183428783374767e-07\n",
      "469 3.9813567864535836e-07\n",
      "470 3.78906370305177e-07\n",
      "471 3.60606429152077e-07\n",
      "472 3.431924544726857e-07\n",
      "473 3.266215738882989e-07\n",
      "474 3.108515218475863e-07\n",
      "475 2.958444897984317e-07\n",
      "476 2.8156322073957514e-07\n",
      "477 2.679733653745154e-07\n",
      "478 2.550390224950344e-07\n",
      "479 2.427305829268188e-07\n",
      "480 2.3101595732868085e-07\n",
      "481 2.198692364516315e-07\n",
      "482 2.0925995898356327e-07\n",
      "483 1.991644601241368e-07\n",
      "484 1.8955574251833427e-07\n",
      "485 1.8041252010643175e-07\n",
      "486 1.7170988140117724e-07\n",
      "487 1.6342924222777256e-07\n",
      "488 1.5554602796498244e-07\n",
      "489 1.4804565890487021e-07\n",
      "490 1.409059200617267e-07\n",
      "491 1.341126494197126e-07\n",
      "492 1.2764555357087008e-07\n",
      "493 1.2149287770877993e-07\n",
      "494 1.1563494607205477e-07\n",
      "495 1.100618655255232e-07\n",
      "496 1.0475532696720864e-07\n",
      "497 9.970730572884467e-08\n",
      "498 9.490074819139776e-08\n",
      "499 9.032846130181207e-08\n"
     ]
    }
   ],
   "source": [
    "# learning rate\n",
    "for t in range(500):\n",
    "    # Forward pass :  compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    # compute and prnt loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "    \n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y) # devia(loss) = 2 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1468.939208984375\n",
      "199 14.87568187713623\n",
      "299 0.22394025325775146\n",
      "399 0.004379940684884787\n",
      "499 0.0002612062089610845\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cpu')\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Create random Tensors for weights\n",
    "# Setting requires_grad = True indicates that we want to compute gradient \n",
    "# with repect to these Tensors during the backward pass.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    \n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        \n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 480.1095275878906\n",
      "199 3.761472225189209\n",
      "299 0.04835880547761917\n",
      "399 0.001113116624765098\n",
      "499 0.00011630377412075177\n"
     ]
    }
   ],
   "source": [
    "# pytorch: defining new autograde functions\n",
    "# pytorch provides autograd operator by defining a subclass of torch\n",
    "# autograd.Function and implementing the forward and backward functions. \n",
    "\n",
    "# possible to implmented custom autograd functions by subclassing\n",
    "# torch.autograd.Function and implementing the forward and backward \n",
    "# passes which operate on Tensors\n",
    "import torch\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "    # in the forward pass we recieve a Tensor containing the input\n",
    "    # and return a Tensor containing the ouput. ctx is a context \n",
    "    # object that can be used to stash information for backward \n",
    "    # computation\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Create random Tensors for weights.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # To apply our Function, we use Function.apply method. We alias this as 'relu'.\n",
    "    relu = MyReLU.apply\n",
    "\n",
    "    # Forward pass: compute predicted y using operations; we compute\n",
    "    # ReLU using our custom autograd operation.\n",
    "    y_pred = relu(x.mm(w1)).mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
